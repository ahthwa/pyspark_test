{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_COUNT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_test(test_count, data):\n",
    "    count_time = []\n",
    "    group_count_time = []\n",
    "\n",
    "    for i in range(test_count):\n",
    "        t0 = time.time()\n",
    "        data.count()\n",
    "        t1 = time.time()\n",
    "        count_time.append(t1 - t0)\n",
    "\n",
    "    print(\"Count Time\")\n",
    "    print(count_time)\n",
    "    print(\"Average Count Time : %f\" %(np.mean(count_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1\n",
    "\n",
    "196M 텍스트 파일 하나를 읽어서 count 테스트  \n",
    "\n",
    "count의 결과에서  \n",
    "\n",
    "* cache를 할 경우 파일을 처음 읽을 때 더 느림\n",
    "* 두번째 이후의 처리속도는 cache여부와 무관하게 비슷했다. cache가 동작하지 않았거나 cache를 하지 않았지만 알아서 메모리에 적재했거나.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file = \"hdfs://ssgslab01/user/ahthwa/pyspark_test/round2_purchaseRecord.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purchase_record = sc.textFile(test_file)\n",
    "purchase_record_cache = sc.textFile(test_file)\n",
    "purchase_record_cache.cache()\n",
    "purchase_record_cache_2 = sc.textFile(test_file).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Not Cached ----\n",
      "Count Time\n",
      "[8.588986873626709, 8.985455989837646, 9.038344860076904, 8.993307113647461, 9.006339073181152]\n",
      "Average Count Time : 8.922487\n",
      "\n",
      "---- Cached-1 ----\n",
      "Count Time\n",
      "[11.52690315246582, 5.477094888687134, 5.453290939331055, 5.580351829528809, 5.484626054763794]\n",
      "Average Count Time : 6.704453\n",
      "\n",
      "---- Cached-2 ----\n",
      "Count Time\n",
      "[11.220871925354004, 5.47505521774292, 5.512097120285034, 5.472071170806885, 5.509972095489502]\n",
      "Average Count Time : 6.638014\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Not Cached ----\")\n",
    "count_test(TEST_COUNT, purchase_record)\n",
    "print(\"\\n---- Cached-1 ----\")\n",
    "count_test(TEST_COUNT, purchase_record_cache)\n",
    "print(\"\\n---- Cached-2 ----\")\n",
    "count_test(TEST_COUNT, purchase_record_cache_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test 2\n",
    "\n",
    "전체 용량 369.8M인 로그 파일 여러개를 읽어서 count, groupby하는 테스트\n",
    "\n",
    "두 번째 이후 count에서 cache를 통해 성능 향상 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file = \"hdfs://ssgslab01/data/wifimon/dashboard/base_log/20160701/part-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baselog = sc.textFile(test_file)\n",
    "baselog_cache = sc.textFile(test_file)\n",
    "baselog_cache.cache()\n",
    "baselog_cache_2 = sc.textFile(test_file).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Not Cached ----\n",
      "Count Time\n",
      "[9.249214172363281, 9.96982192993164, 9.994314193725586, 10.000025033950806, 10.008059978485107]\n",
      "Average Count Time : 9.844287\n",
      "\n",
      "---- Cached-1 ----\n",
      "Count Time\n",
      "[12.327146053314209, 3.0349879264831543, 2.962813138961792, 2.9769110679626465, 2.971198081970215]\n",
      "Average Count Time : 4.854611\n",
      "\n",
      "---- Cached-2 ----\n",
      "Count Time\n",
      "[13.09050989151001, 3.0133249759674072, 2.985042095184326, 2.971369981765747, 2.985313892364502]\n",
      "Average Count Time : 5.009112\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Not Cached ----\")\n",
    "count_test(TEST_COUNT, baselog)\n",
    "print(\"\\n---- Cached-1 ----\")\n",
    "count_test(TEST_COUNT, baselog_cache)\n",
    "print(\"\\n---- Cached-2 ----\")\n",
    "count_test(TEST_COUNT, baselog_cache_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def groupby_count(data, key_idx):\n",
    "    return data.map(lambda x:x.strip().split('\\t')).map(lambda x:(x[key_idx], 1)).reduceByKey(lambda a,b:a+b)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3\n",
    "\n",
    "group by할 데이터를 한번 읽어서 재사용, 한번 읽어서 cache, 매번 읽는 경우를 비교함.\n",
    "\n",
    "* 데이터를 로딩하는 것이 매번 읽는 것 보다 빠르다(당연히)  \n",
    "* cache를 명시적으로 사용하지 않아도 cache 한 것과 비슷한 속도를 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file = \"hdfs://ssgslab01/data/wifimon/dashboard/base_log/20160708/part-*\"\n",
    "baselog_2 = sc.textFile(test_file)\n",
    "\n",
    "def groupby_test_1(test_count, data):\n",
    "    group_count_time = []\n",
    "\n",
    "    for i in range(test_count):\n",
    "        t0 = time.time()\n",
    "        groupby_count(data, 0)\n",
    "        t1 = time.time()\n",
    "        group_count_time.append(t1 - t0)\n",
    "    \n",
    "    print(\"Group by Time\")\n",
    "    print(group_count_time)\n",
    "    print(\"Average Group By Time : %f\" %(np.mean(group_count_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by Time\n",
      "[0.06061100959777832, 0.014039039611816406, 0.014146089553833008, 0.013869047164916992, 0.013686895370483398]\n",
      "Average Group By Time : 0.023270\n"
     ]
    }
   ],
   "source": [
    "groupby_test_1(TEST_COUNT, baselog_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file = \"hdfs://ssgslab01/data/wifimon/dashboard/base_log/20160715/part-*\"\n",
    "baselog_3 = sc.textFile(test_file).cache()\n",
    "\n",
    "def groupby_test_2(test_count, data):\n",
    "    group_count_time = []\n",
    "\n",
    "    for i in range(test_count):\n",
    "        t0 = time.time()\n",
    "        groupby_count(data, 0)\n",
    "        t1 = time.time()\n",
    "        group_count_time.append(t1 - t0)\n",
    "    \n",
    "    print(\"Group by Time\")\n",
    "    print(group_count_time)\n",
    "    print(\"Average Group By Time : %f\" %(np.mean(group_count_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by Time\n",
      "[0.04703497886657715, 0.025379180908203125, 0.013731002807617188, 0.013928890228271484, 0.013622045516967773]\n",
      "Average Group By Time : 0.022739\n"
     ]
    }
   ],
   "source": [
    "groupby_test_2(TEST_COUNT, baselog_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file = \"hdfs://ssgslab01/data/wifimon/dashboard/base_log/20160722/part-*\"\n",
    "def groupby_test_3(test_count, test_file):\n",
    "    group_count_time = []\n",
    "\n",
    "    for i in range(test_count):\n",
    "        data = sc.textFile(test_file)\n",
    "        t0 = time.time()\n",
    "        groupby_count(data, 0)\n",
    "        t1 = time.time()\n",
    "        group_count_time.append(t1 - t0)\n",
    "    \n",
    "    print(\"Group by Time\")\n",
    "    print(group_count_time)\n",
    "    print(\"Average Group By Time : %f\" %(np.mean(group_count_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by Time\n",
      "[0.04830193519592285, 0.04689216613769531, 0.04421401023864746, 0.052915096282958984, 0.04367995262145996]\n",
      "Average Group By Time : 0.047201\n"
     ]
    }
   ],
   "source": [
    "groupby_test_3(TEST_COUNT, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.6.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
